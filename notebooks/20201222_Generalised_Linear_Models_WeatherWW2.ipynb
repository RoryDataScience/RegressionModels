{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Start Date** <br>\n",
    "17th December 2020 <br>\n",
    "\n",
    "**Data Sources** <br>\n",
    "https://www.kaggle.com/usaf/world-war-ii/notebooks <br> \n",
    "https://www.kaggle.com/smid80/weatherww2/data <br>\n",
    "\n",
    "**Background** <br>\n",
    "Aerial Bombing Operations in WW2 - Bombing operations data <br>\n",
    "\n",
    "This dataset consists of digitized paper mission reports from WWII. Each record includes the date, conflict, geographic location, and other data elements to form a live-action sequence of air warfare from 1939 to 1945. The records include U.S. and Royal Air Force data, in addition to some Australian, New Zealand and South African air force missions.\n",
    "\n",
    "Weather Conditions in WW2 (Weather Stations / Weather Conditions) <br>\n",
    "The dataset contains information on weather conditions recorded on each day at various weather stations around the world. Information includes precipitation, snowfall, temperatures, wind speed and whether the day included thunder storms or other poor weather conditions.\n",
    "\n",
    "**Aim of this project** <br>\n",
    "Use Sweetviz - A powerful package to speed up EDA, saving reports as HTML files and with the ability to compare test and train datasets \n",
    "Impletment the use of Ridge Plots as part of EDA to understand variabe distribution analysis \n",
    "One method of Outlier Detection & Analysis\n",
    "Implement a GLM model that predicts the maximum weather temperature (based on the minimum temperature)\n",
    "Test Assumptions of GLMs & Residual Analysis: Correlation of errors with predictor variables\n",
    "Dockerise the notebook\n",
    "\n",
    "\n",
    "**Analysis regarding Data Quality** <br>\n",
    "Understanding of the sampling procedure \n",
    "- Since our project team did not participate in planning the study or data collection, it is possible that we are missing crucial context which could render our conclusions invalid. <br>\n",
    "\n",
    "Potential biases <br> \n",
    "Real-world actions that generated the data you inherited <br>\n",
    "\n",
    "**Objectives & Hypothesises to Test (max. 10)** <br>\n",
    "<u>Exploratory Analysis</u>\n",
    "- High level discriptive statistics \n",
    "- Do any values look to be recorded to accommodate missing values? e.g. 999, 9999 etc.\n",
    "- Assessment of feature distributions\n",
    "- Assessment of feature relationships:\n",
    "    - What defines the feature 'poor weather' conditions?\n",
    "    - Is there a relationship between the daily minimum and maximum temperature (TimeSeries Analysis)?\n",
    "    - It is expected that average temperatures are colder in winter months than summer months\n",
    "    - It is expected that more snowfall occurs in the winter months (for northern hemisphere regions)\n",
    "    - It is expected that more Precipitation occurs in the winter months (for northern hemisphere)\n",
    "    - It is expected that lower temperatures correlate with higher snowfall and precipation \n",
    "    - It is expected that higher levels above the sea have greater precipation\n",
    "    - It is expected that the accuracy of recordings based on stations may not be uniform (outlier detection)\n",
    "<br>\n",
    "\n",
    "**Statistical Model/Machine Learning Applications**\n",
    "- Create a dummy model (Predict the average temperature for that monthly/quarter)\n",
    "- Explain the train/test split\n",
    "- Predict the maximum temperature given the minimum temperature (GLM Models & Bayesian Versions)?\n",
    "- Explain appropriate error metric\n",
    "- Explain class balance and any required action\n",
    "- Explain what features are developed and transformations applied\n",
    "- Explain if the model is exhibiting high bias or high variance and how this can be improved\n",
    "    - Plot learning curves to deduce high bias/high variance and conclude what means could be applied to solve these issues\n",
    "- Explain where the model seems to perform poorly - In what situations does the model make mistakes?\n",
    "\n",
    "**Additional Learning notes from Reviewing 3 other Kaggle Notebooks** <br> \n",
    "\n",
    "**Next steps** <br>\n",
    "\n",
    "**References**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Package Requirements\n",
    "import os\n",
    "import sys\n",
    "# !{sys.executable} -m pip install markdown\n",
    "# !{sys.executable} -m pip install sweetviz\n",
    "# !{sys.executable} -m pip install joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "\n",
    "# Data Exploration and Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv\n",
    "import joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Rej1992/Documents/GitHub/RegressionModels/notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_bombing_data = pd.read_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/01_raw/ww2_boming_operations.csv')\n",
    "weather_summary = pd.read_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/01_raw/WeatherTempPrediction.csv')\n",
    "weather_station_location = pd.read_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/01_raw/WeatherStationLocations.csv')\n",
    "\n",
    "data_list = []\n",
    "data_list.append(aerial_bombing_data)\n",
    "data_list.append(weather_summary)\n",
    "data_list.append(weather_station_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State the assumptions youâ€™re being forced to make.\n",
    "# Write up caveat notes to be included in the appendix of your final report\n",
    "# Write cautionary notes that warn the decision-maker (and your other readers) that conclusions from the study will \n",
    "# need to be downgraded due to potential data issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Dimensions\n",
      "(178281, 46)\n",
      "\n",
      "Dataframe Columns and respective types\n",
      "Mission ID                                 int64\n",
      "Mission Date                              object\n",
      "Theater of Operations                     object\n",
      "Country                                   object\n",
      "Air Force                                 object\n",
      "Unit ID                                   object\n",
      "Aircraft Series                           object\n",
      "Callsign                                  object\n",
      "Mission Type                              object\n",
      "Takeoff Base                              object\n",
      "Takeoff Location                          object\n",
      "Takeoff Latitude                          object\n",
      "Takeoff Longitude                        float64\n",
      "Target ID                                 object\n",
      "Target Country                            object\n",
      "Target City                               object\n",
      "Target Type                               object\n",
      "Target Industry                           object\n",
      "Target Priority                           object\n",
      "Target Latitude                          float64\n",
      "Target Longitude                         float64\n",
      "Altitude (Hundreds of Feet)              float64\n",
      "Airborne Aircraft                        float64\n",
      "Attacking Aircraft                       float64\n",
      "Bombing Aircraft                         float64\n",
      "Aircraft Returned                        float64\n",
      "Aircraft Failed                          float64\n",
      "Aircraft Damaged                         float64\n",
      "Aircraft Lost                            float64\n",
      "High Explosives                          float64\n",
      "High Explosives Type                      object\n",
      "High Explosives Weight (Pounds)           object\n",
      "High Explosives Weight (Tons)            float64\n",
      "Incendiary Devices                       float64\n",
      "Incendiary Devices Type                   object\n",
      "Incendiary Devices Weight (Pounds)       float64\n",
      "Incendiary Devices Weight (Tons)         float64\n",
      "Fragmentation Devices                    float64\n",
      "Fragmentation Devices Type                object\n",
      "Fragmentation Devices Weight (Pounds)    float64\n",
      "Fragmentation Devices Weight (Tons)      float64\n",
      "Total Weight (Pounds)                    float64\n",
      "Total Weight (Tons)                      float64\n",
      "Time Over Target                          object\n",
      "Bomb Damage Assessment                    object\n",
      "Source ID                                float64\n",
      "dtype: object\n",
      "\n",
      "Percentage of Missing Data\n",
      "Mission ID                                0.000000\n",
      "Mission Date                              0.000000\n",
      "Theater of Operations                     1.771361\n",
      "Country                                  29.047964\n",
      "Air Force                                29.076009\n",
      "Unit ID                                  71.442274\n",
      "Aircraft Series                           0.065066\n",
      "Callsign                                 99.988221\n",
      "Mission Type                             73.532794\n",
      "Takeoff Base                             98.102434\n",
      "Takeoff Location                         98.127675\n",
      "Takeoff Latitude                         98.327921\n",
      "Takeoff Longitude                        98.328481\n",
      "Target ID                                28.536412\n",
      "Target Country                            0.335986\n",
      "Target City                               1.269344\n",
      "Target Type                              17.899271\n",
      "Target Industry                          29.056377\n",
      "Target Priority                          24.433899\n",
      "Target Latitude                           4.888911\n",
      "Target Longitude                          4.901251\n",
      "Altitude (Hundreds of Feet)              32.227214\n",
      "Airborne Aircraft                        53.869453\n",
      "Attacking Aircraft                       29.825388\n",
      "Bombing Aircraft                         54.222828\n",
      "Aircraft Returned                        99.925399\n",
      "Aircraft Failed                          99.861455\n",
      "Aircraft Damaged                         99.978685\n",
      "Aircraft Lost                            99.911376\n",
      "High Explosives                          80.515591\n",
      "High Explosives Type                     76.472535\n",
      "High Explosives Weight (Pounds)          98.866396\n",
      "High Explosives Weight (Tons)            17.994066\n",
      "Incendiary Devices                       98.158525\n",
      "Incendiary Devices Type                  96.904325\n",
      "Incendiary Devices Weight (Pounds)       99.800315\n",
      "Incendiary Devices Weight (Tons)         85.566606\n",
      "Fragmentation Devices                    96.764658\n",
      "Fragmentation Devices Type               96.766341\n",
      "Fragmentation Devices Weight (Pounds)    99.891183\n",
      "Fragmentation Devices Weight (Tons)      90.519461\n",
      "Total Weight (Pounds)                    98.811427\n",
      "Total Weight (Tons)                       6.603620\n",
      "Time Over Target                         99.613531\n",
      "Bomb Damage Assessment                   99.941665\n",
      "Source ID                                 2.268890\n",
      "dtype: float64\n",
      "\n",
      "Dataframe Dimensions\n",
      "(119040, 31)\n",
      "\n",
      "Dataframe Columns and respective types\n",
      "STA              int64\n",
      "Date            object\n",
      "Precip          object\n",
      "WindGustSpd    float64\n",
      "MaxTemp        float64\n",
      "MinTemp        float64\n",
      "MeanTemp       float64\n",
      "Snowfall        object\n",
      "PoorWeather     object\n",
      "YR               int64\n",
      "MO               int64\n",
      "DA               int64\n",
      "PRCP            object\n",
      "DR             float64\n",
      "SPD            float64\n",
      "MAX            float64\n",
      "MIN            float64\n",
      "MEA            float64\n",
      "SNF             object\n",
      "SND            float64\n",
      "FT             float64\n",
      "FB             float64\n",
      "FTI            float64\n",
      "ITH            float64\n",
      "PGT            float64\n",
      "TSHDSBRSGF      object\n",
      "SD3            float64\n",
      "RHX            float64\n",
      "RHN            float64\n",
      "RVG            float64\n",
      "WTE            float64\n",
      "dtype: object\n",
      "\n",
      "Percentage of Missing Data\n",
      "STA              0.000000\n",
      "Date             0.000000\n",
      "Precip           0.000000\n",
      "WindGustSpd     99.553091\n",
      "MaxTemp          0.000000\n",
      "MinTemp          0.000000\n",
      "MeanTemp         0.000000\n",
      "Snowfall         0.976983\n",
      "PoorWeather     71.239079\n",
      "YR               0.000000\n",
      "MO               0.000000\n",
      "DA               0.000000\n",
      "PRCP             1.622984\n",
      "DR              99.552251\n",
      "SPD             99.553091\n",
      "MAX              0.398185\n",
      "MIN              0.393145\n",
      "MEA              0.418347\n",
      "SNF              0.976983\n",
      "SND             95.326781\n",
      "FT             100.000000\n",
      "FB             100.000000\n",
      "FTI            100.000000\n",
      "ITH            100.000000\n",
      "PGT             99.558972\n",
      "TSHDSBRSGF      71.239079\n",
      "SD3            100.000000\n",
      "RHX            100.000000\n",
      "RHN            100.000000\n",
      "RVG            100.000000\n",
      "WTE            100.000000\n",
      "dtype: float64\n",
      "\n",
      "Dataframe Dimensions\n",
      "(161, 8)\n",
      "\n",
      "Dataframe Columns and respective types\n",
      "WBAN                  int64\n",
      "NAME                 object\n",
      "STATE/COUNTRY ID     object\n",
      "LAT                  object\n",
      "LON                  object\n",
      "ELEV                  int64\n",
      "Latitude            float64\n",
      "Longitude           float64\n",
      "dtype: object\n",
      "\n",
      "Percentage of Missing Data\n",
      "WBAN                0.0\n",
      "NAME                0.0\n",
      "STATE/COUNTRY ID    0.0\n",
      "LAT                 0.0\n",
      "LON                 0.0\n",
      "ELEV                0.0\n",
      "Latitude            0.0\n",
      "Longitude           0.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data_list:\n",
    "    print(\"Dataframe Dimensions\")\n",
    "    print(i.shape)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Dataframe Columns and respective types\")\n",
    "    print(i.dtypes)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Percentage of Missing Data\")\n",
    "    print(i.isnull().sum() * 100 / len(i))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "161\n",
      "Sets are of the same data type:  True\n",
      "Stations that are uncommon across both sets:  [15605, 15604]\n"
     ]
    }
   ],
   "source": [
    "# Investiage options to link the dataframes with a unique key: weather_summary and weather_station_location look to be \n",
    "# connected via STA and WBAN respectively \n",
    "def uncommon_elements(list1, list2):\n",
    "    ## Add something clever so the look up is always against the set with the largest number of unique records\n",
    "    \n",
    "    return [element for element in list2 if element not in list1]\n",
    "\n",
    "STA = set(weather_summary.STA)\n",
    "print(len(STA))\n",
    "\n",
    "WBAN = set(weather_station_location.WBAN)\n",
    "print(len(WBAN))\n",
    "\n",
    "print('Sets are of the same data type: ', type(weather_summary.STA) == type(weather_station_location.WBAN))\n",
    "\n",
    "print('Stations that are uncommon across both sets: ', uncommon_elements(STA, WBAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119040\n"
     ]
    }
   ],
   "source": [
    "combined_data = pd.merge(weather_summary, \n",
    "                         weather_station_location, \n",
    "                         how = 'inner', # takes care of only keeping records in both sets\n",
    "                         left_on='STA',\n",
    "                         right_on='WBAN')\n",
    "\n",
    "print(len(combined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns for Combined Data\n",
    "**STA**\n",
    "- STA: represent the Weather Station\n",
    "- Not all STA codes represent the same time frequency \n",
    "- Object Data Type\n",
    "\n",
    "**Date** \n",
    "- Date has been split into DA MO and YR respectively, note the century has been dropped when recording the YR\n",
    "- Date Data Type (will require engineering in order to be used for ML\n",
    "\n",
    "**Precip** \n",
    "- Precipitation in mm. This consists of numerical values and 'T' for 16,754 entries. This looks to be a mistake in the data collection (Impute precip == 0 for these cases)\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**MaxTemp and MinTemp** \n",
    "- These are features that have been transformed into celcius from fahrenheit readings MAX/MIN and these have been recorded to 6 decimal places. The degrees celcius value has additionally been converted to an average. Using celcius will have a smaller range than the fahrenheit records. Patterns may be more easily seen based fahrenheit columns \n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**MEA** \n",
    "- This is the mean for the fahrenheit MAX / MIN columns and this has been rounded to 1 d.p. Drop this columns and calculate the extact mean value\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**Snowfall**\n",
    "- This looks to be measures in terms of the amount of snow that fell in mm. The units are not obvious so there are two options\n",
    "- Either assume the units are centiments by attempting to research more about the data OR normalise all the columns so they are on the same scale\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**SNF**\n",
    "- After research it is unclear what SNF relates too and seems to gave a range of 0 - 3.4 (Agree to remove)\n",
    "- This supports the necessity to normalise the data for the numeric columns due to the possibility of differing units across columns\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**PRCP**\n",
    "- This column looks to have been scaled by a factor of 1/25.4*Precip (Agree to remove)\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**TSHDSBRSGF**\n",
    "- This is a repeat for PoorWeather so can be removed\n",
    "\n",
    "**WBAN**\n",
    "- Same as STA, representing the Weather Station\n",
    "- Not all Weather Stations are located in the USA (unique STATE/COUNTRY ID = 63)\n",
    "- This will be duplicated due to the merge so can be removed \n",
    "- Object Data Type\n",
    "\n",
    "**NAME**\n",
    "- This is the name of the weather station. It has a many:1 relationship with State/Country ID i.e. more than one station can be present per country \n",
    "- Object Data Type (Nominal)\n",
    "\n",
    "**STATE/COUNTRY ID**\n",
    "- This is the location of the weather station at state/country level\n",
    "- Object Data Type (Nominal)\n",
    "\n",
    "**LAT**\n",
    "- This is the decimal latitude in string format \n",
    "\n",
    "**LON**\n",
    "- This is the decimal latitude in string format \n",
    "\n",
    "**ELEV**\n",
    "- Explanation not given - Expected to be level above the sea \n",
    "- Note that an elevation of 9999 means unknown\n",
    "- Numeric (float) Data Type\n",
    "\n",
    "**Latitude**\n",
    "- This is the decimal latitude calculated from the LAT/LON provided (use this over string as in format for ML)\n",
    "\n",
    "**Longitude**\n",
    "- This is the decimal longitude calculated from the LAT/LON provided (use this over string as in format for ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - Remove duplicate Rows & Columns\n",
    "- Remove all columns that exhibit over 90% missing values\n",
    "- Remove celcius columns 'MaxTemp', 'MinTemp', 'MeanTemp' and 'MEA'\n",
    "- Remove duplicated/scaled columns: 'PRCP', 'TSHDSBRSGF'\n",
    "- Remove PoorWeather for the inital analysis as unclear how the data has been recorded \n",
    "- Remove the primary key to join dataframes SNF & WBAN\n",
    "- Remove LAT as string format\n",
    "- Remove LON as string format\n",
    "- Remove those columns with zero variance\n",
    "- Remove duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows for index:  Int64Index([94660, 94661, 94662, 94663, 94664, 94665, 94666, 94667, 94668,\n",
      "            94669],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Handling missing data - Remove any columns with over 90% missing data \n",
    "def remove_missing_values(data, thresold_limit = 0.9):\n",
    "    \n",
    "    return data.loc[:, data.isnull().sum() < thresold_limit*data.shape[0]]\n",
    "\n",
    "combined_data = remove_missing_values(combined_data)\n",
    "\n",
    "# Remove additional columns based on explanation above\n",
    "combined_data.drop(['MaxTemp', \n",
    "                    'MinTemp', \n",
    "                    'MeanTemp', \n",
    "                    'MEA', \n",
    "                    'TSHDSBRSGF', \n",
    "                    'PRCP', \n",
    "                    #'PoorWeather', \n",
    "                    'SNF', \n",
    "                    'WBAN',\n",
    "                    'LAT', \n",
    "                    'LON'], axis=1, inplace=True)\n",
    "\n",
    "# Data Quality Expectations: Test for zero variance \n",
    "combined_data = combined_data.loc[:, combined_data.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "# Data Quality Expectations: Duplicated Records\n",
    "print('Duplicated rows for index: ', combined_data[combined_data.duplicated()].index)\n",
    "#print(len(combined_data))\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "#print(len(combined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- Understand and update data to correct type [x]\n",
    "- Check that variables are within a range expected \n",
    "- Assessment of categorical labels and confirm they are as expected\n",
    "- Evaluate where missing data exists and how to deal with these fields\n",
    "- Data represents logical coherence (e.g. underaged cannot hold a driving licence)\n",
    "- Reformatting: Drop/Rename columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Date\n",
    "def correct_dates(data, cols):\n",
    "    \n",
    "    return pd.to_datetime(combined_data[cols], format = '%Y-%m-%d')\n",
    "\n",
    "# Correct Object Types\n",
    "def correct_objects(data, cols):\n",
    "    \n",
    "    return data[cols].astype('object')\n",
    "\n",
    "# Correct String Types\n",
    "def correct_string(data, cols):\n",
    "    \n",
    "    return data[cols].astype(str)\n",
    "\n",
    "combined_data.Date = correct_dates(combined_data, 'Date')\n",
    "\n",
    "combined_data.STA = correct_objects(combined_data, 'STA')\n",
    "combined_data.YR = correct_objects(combined_data, 'YR')\n",
    "combined_data.MO = correct_objects(combined_data, 'MO')\n",
    "combined_data.DA = correct_objects(combined_data, 'DA')\n",
    "\n",
    "combined_data.Snowfall = correct_string(combined_data, 'Snowfall')\n",
    "combined_data.PoorWeather = correct_string(combined_data, 'PoorWeather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134fede13e344f798b9ae11012955aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=16.0), HTML(value='')), lâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "my_report = sv.analyze(combined_data)\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with Missing/Inaccurate values and correct data types \n",
    "def impute_missing_values(data, cols):\n",
    "    \n",
    "    return np.where((data[cols] == 'T') | (data[cols] == ' '), 0, data[cols])\n",
    "\n",
    "# Correct float types\n",
    "def correct_floats(data, cols):\n",
    "    \n",
    "    return data[cols].astype('float')\n",
    "\n",
    "# As the target variable contains 4% missing values remove these to avoid inaccurate assumptions\n",
    "def remove_missing_max(data):\n",
    "    \n",
    "    return data[data.loc[:, 'MAX'].notnull()]\n",
    "\n",
    "def remove_missing_min(data):\n",
    "    \n",
    "    return data[data.loc[:, 'MIN'].notnull()]\n",
    "\n",
    "combined_data.Precip = impute_missing_values(combined_data, 'Precip')\n",
    "combined_data.Precip = correct_floats(combined_data, 'Precip')\n",
    "\n",
    "combined_data = remove_missing_max(combined_data)\n",
    "combined_data = remove_missing_min(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [STA, Date, Precip, Snowfall, PoorWeather, YR, MO, DA, MAX, MIN, NAME, STATE/COUNTRY ID, ELEV, Latitude, Longitude]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [STA, Date, Precip, Snowfall, PoorWeather, YR, MO, DA, MAX, MIN, NAME, STATE/COUNTRY ID, ELEV, Latitude, Longitude]\n",
      "Index: []\n",
      "STA                 0.0\n",
      "Date                0.0\n",
      "Precip              0.0\n",
      "Snowfall            0.0\n",
      "PoorWeather         0.0\n",
      "YR                  0.0\n",
      "MO                  0.0\n",
      "DA                  0.0\n",
      "MAX                 0.0\n",
      "MIN                 0.0\n",
      "NAME                0.0\n",
      "STATE/COUNTRY ID    0.0\n",
      "ELEV                0.0\n",
      "Latitude            0.0\n",
      "Longitude           0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify that the above logic has been correctly applied \n",
    "print(combined_data[combined_data.loc[:, 'MAX'].isnull()])\n",
    "print(combined_data[combined_data.loc[:, 'MIN'].isnull()])\n",
    "print((combined_data.isnull().sum() * 100) / len(combined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Combination Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precip</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>ELEV</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precip</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>0.091849</td>\n",
       "      <td>0.080995</td>\n",
       "      <td>-0.102590</td>\n",
       "      <td>0.009129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX</th>\n",
       "      <td>0.004358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873746</td>\n",
       "      <td>0.043016</td>\n",
       "      <td>-0.554533</td>\n",
       "      <td>0.044043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>0.091849</td>\n",
       "      <td>0.873746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060579</td>\n",
       "      <td>-0.601654</td>\n",
       "      <td>-0.089958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEV</th>\n",
       "      <td>0.080995</td>\n",
       "      <td>0.043016</td>\n",
       "      <td>0.060579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.068801</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.102590</td>\n",
       "      <td>-0.554533</td>\n",
       "      <td>-0.601654</td>\n",
       "      <td>-0.068801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.044043</td>\n",
       "      <td>-0.089958</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.130366</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precip       MAX       MIN      ELEV  Latitude  Longitude\n",
       "Precip     1.000000  0.004358  0.091849  0.080995 -0.102590   0.009129\n",
       "MAX        0.004358  1.000000  0.873746  0.043016 -0.554533   0.044043\n",
       "MIN        0.091849  0.873746  1.000000  0.060579 -0.601654  -0.089958\n",
       "ELEV       0.080995  0.043016  0.060579  1.000000 -0.068801   0.000770\n",
       "Latitude  -0.102590 -0.554533 -0.601654 -0.068801  1.000000  -0.130366\n",
       "Longitude  0.009129  0.044043 -0.089958  0.000770 -0.130366   1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = combined_data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling nominal and ordinal categorical values\n",
    "Types: \n",
    "- Ordinal: Convert into numeric values retaining the datas natural order\n",
    "- Nominal: One Hot encoding/Label Encoding\n",
    "- Dichotomous (Binary): Convert values into indicator values 1/0 <br>\n",
    "The only columns that require revision at this stage are 'NAME' and 'STATE/COUNTRY ID'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STA', 'Snowfall', 'PoorWeather', 'YR', 'MO', 'DA', 'NAME',\n",
       "       'STATE/COUNTRY ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_category_datatype(data, cols):\n",
    "    \n",
    "    return data[cols].astype('category')\n",
    "\n",
    "combined_data.NAME = correct_category_datatype(combined_data, 'NAME')\n",
    "combined_data['STATE/COUNTRY ID'] = correct_category_datatype(combined_data, 'STATE/COUNTRY ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 118532 entries, 0 to 119039\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   STA               118532 non-null  object        \n",
      " 1   Date              118532 non-null  datetime64[ns]\n",
      " 2   Precip            118532 non-null  float64       \n",
      " 3   Snowfall          118532 non-null  object        \n",
      " 4   PoorWeather       118532 non-null  object        \n",
      " 5   YR                118532 non-null  object        \n",
      " 6   MO                118532 non-null  object        \n",
      " 7   DA                118532 non-null  object        \n",
      " 8   MAX               118532 non-null  float64       \n",
      " 9   MIN               118532 non-null  float64       \n",
      " 10  NAME              118532 non-null  category      \n",
      " 11  STATE/COUNTRY ID  118532 non-null  category      \n",
      " 12  ELEV              118532 non-null  int64         \n",
      " 13  Latitude          118532 non-null  float64       \n",
      " 14  Longitude         118532 non-null  float64       \n",
      "dtypes: category(2), datetime64[ns](1), float64(5), int64(1), object(6)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas `.get_dummies()` method\n",
    "NAME_dummies_df = pd.concat([combined_data, pd.get_dummies(combined_data['NAME'], prefix='category')],axis=1)\n",
    "STATE_dummies_df = pd.concat([combined_data, pd.get_dummies(combined_data['STATE/COUNTRY ID'], prefix='category')],axis=1)\n",
    "\n",
    "# Now drop the original 'category' column (you don't need it anymore)\n",
    "NAME_dummies_df.drop(['NAME'],axis=1, inplace=True)\n",
    "STATE_dummies_df.drop(['STATE/COUNTRY ID'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "prefix = 'category'\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe = ohe.fit(combined_data[['category']])\n",
    "onehot_encoded = ohe.transform(combined_data[['category']])\n",
    "features_names_prefixed = [ f\"{prefix}_{category}\" for category in onehot_encoder.categories_[0]]\n",
    "category_enncoded_df = pd.concat([combined_data, pd.DataFrame(onehot_encoded, columns=features_names_prefixed)], axis=1)\n",
    "# now drop the original 'category' column (you don't need it anymore)\n",
    "category_enncoded_df.drop(['category'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis \n",
    "**Hypothesis & Expectations to Test**\n",
    "- Is this a Global study? What are the locations associated with the experiment? [x]\n",
    "- High level discriptive statistics [x]\n",
    "- Assessment of feature distributions [x]\n",
    "- Do any values look to be recorded to accommodate missing values? e.g. 999, 9999 etc.\n",
    "- Assessment of feature relationships:\n",
    "    - What is the relationship of each variable with the target?\n",
    "- Data Integrity Preprocessing Steps\n",
    "    - It is expected that average temperatures are colder in winter months than summer months\n",
    "    - It is expected that more snowfall occurs in the winter months (for northern hemisphere regions)\n",
    "    - It is expected that more Precipitation occurs in the winter months (for northern hemisphere)\n",
    "    - It is expected that lower temperatures correlate with higher snowfall and precipation \n",
    "    - It is expected that higher levels above the sea have greater precipation\n",
    "    - It is expected that the accuracy of recordings based on stations may not be uniform (outlier detection)\n",
    "- Create a function that differentiates between the Northern & Southern Hemisphere if using monthly data\n",
    "- Time Series Analysis (max. 3 graphs/analyses)\n",
    "\n",
    "**References** <br>\n",
    "https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34 <br>\n",
    "https://medium.com/analytics-vidhya/how-to-plot-data-on-a-world-map-in-python-25cf9733c3dd <br>\n",
    "https://towardsdatascience.com/pandas-profiling-sweetviz-8849704cadd7 <br>\n",
    "https://towardsdatascience.com/ridgeline-plots-the-perfect-way-to-visualize-data-distributions-with-python-de99a5493052 <br>\n",
    "https://towardsdatascience.com/all-you-want-to-know-about-preprocessing-data-preparation-b6c2866071d4 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this a Global study? What are the locations associated with the experiment?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data doesnâ€™t have duplicates because of whitespaces, lower/upper cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GH', 'LI', 'GY', 'BZ', 'PM', ..., 'NG', 'SO', 'AU', 'NH', 'FJ']\n",
       "Length: 63\n",
       "Categories (63, object): ['GH', 'LI', 'GY', 'BZ', ..., 'SO', 'AU', 'NH', 'FJ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['STATE/COUNTRY ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCRA', 'CAPE PALMAS', 'FISHERMANS LAKE', 'MARSHALL/ROBERTS FIELD', 'GEORGETOWN', ..., 'MACKAY', 'ARCHER', 'AMBERLY', 'ROCKHAMPTON', 'BRISBANE']\n",
       "Length: 157\n",
       "Categories (157, object): ['ACCRA', 'CAPE PALMAS', 'FISHERMANS LAKE', 'MARSHALL/ROBERTS FIELD', ..., 'ARCHER', 'AMBERLY', 'ROCKHAMPTON', 'BRISBANE']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.NAME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NAME</th>\n",
       "      <th>ABADAN</th>\n",
       "      <th>ACCRA</th>\n",
       "      <th>ADANA</th>\n",
       "      <th>AGRA</th>\n",
       "      <th>AIN EL</th>\n",
       "      <th>AMBERLY</th>\n",
       "      <th>AMENDOLA</th>\n",
       "      <th>AMENDOLA/MU 9</th>\n",
       "      <th>AMIRABAD POST</th>\n",
       "      <th>AMURI/FIELD AAF</th>\n",
       "      <th>...</th>\n",
       "      <th>TELERGMA</th>\n",
       "      <th>TINDOUF</th>\n",
       "      <th>TONGATABU ISLAND</th>\n",
       "      <th>TOUAHAR</th>\n",
       "      <th>VAL DE CANS</th>\n",
       "      <th>WALLER/BWI</th>\n",
       "      <th>WARRINGTON</th>\n",
       "      <th>WHEELER/AFB 810.1</th>\n",
       "      <th>WHEELUS</th>\n",
       "      <th>WILLEMSTAD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE/COUNTRY ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>502</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TU</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NAME              ABADAN  ACCRA  ADANA  AGRA  AIN EL  AMBERLY  AMENDOLA  \\\n",
       "STATE/COUNTRY ID                                                          \n",
       "AL                     0      0      0     0     383        0         0   \n",
       "AT                     0      0      0     0       0        0         0   \n",
       "AU                     0      0      0     0       0      847         0   \n",
       "AZ                     0      0      0     0       0        0         0   \n",
       "BA                     0      0      0     0       0        0         0   \n",
       "...                  ...    ...    ...   ...     ...      ...       ...   \n",
       "TI                     0      0      0     0       0        0         0   \n",
       "TO                     0      0      0     0       0        0         0   \n",
       "TS                     0      0      0     0       0        0         0   \n",
       "TU                     0      0    260     0       0        0         0   \n",
       "UK                     0      0      0     0       0        0         0   \n",
       "\n",
       "NAME              AMENDOLA/MU 9  AMIRABAD POST  AMURI/FIELD AAF  ...  \\\n",
       "STATE/COUNTRY ID                                                 ...   \n",
       "AL                            0              0                0  ...   \n",
       "AT                            0              0                0  ...   \n",
       "AU                            0              0                0  ...   \n",
       "AZ                            0              0                0  ...   \n",
       "BA                            0              0                0  ...   \n",
       "...                         ...            ...              ...  ...   \n",
       "TI                            0              0                0  ...   \n",
       "TO                            0              0                0  ...   \n",
       "TS                            0              0                0  ...   \n",
       "TU                            0              0                0  ...   \n",
       "UK                            0              0                0  ...   \n",
       "\n",
       "NAME              TELERGMA  TINDOUF  TONGATABU ISLAND  TOUAHAR  VAL DE CANS  \\\n",
       "STATE/COUNTRY ID                                                              \n",
       "AL                     502      818                 0        0            0   \n",
       "AT                       0        0                 0        0            0   \n",
       "AU                       0        0                 0        0            0   \n",
       "AZ                       0        0                 0        0            0   \n",
       "BA                       0        0                 0        0            0   \n",
       "...                    ...      ...               ...      ...          ...   \n",
       "TI                       0        0                 0        0            0   \n",
       "TO                       0        0               179        0            0   \n",
       "TS                       0        0                 0        0            0   \n",
       "TU                       0        0                 0        0            0   \n",
       "UK                       0        0                 0        0            0   \n",
       "\n",
       "NAME              WALLER/BWI  WARRINGTON  WHEELER/AFB 810.1  WHEELUS  \\\n",
       "STATE/COUNTRY ID                                                       \n",
       "AL                         0           0                  0        0   \n",
       "AT                         0           0                  0        0   \n",
       "AU                         0           0                  0        0   \n",
       "AZ                         0           0                  0        0   \n",
       "BA                         0           0                  0        0   \n",
       "...                      ...         ...                ...      ...   \n",
       "TI                         0           0                  0        0   \n",
       "TO                         0           0                  0        0   \n",
       "TS                         0           0                  0        0   \n",
       "TU                         0           0                  0        0   \n",
       "UK                         0         295                  0        0   \n",
       "\n",
       "NAME              WILLEMSTAD  \n",
       "STATE/COUNTRY ID              \n",
       "AL                         0  \n",
       "AT                         0  \n",
       "AU                         0  \n",
       "AZ                         0  \n",
       "BA                         0  \n",
       "...                      ...  \n",
       "TI                         0  \n",
       "TO                         0  \n",
       "TS                         0  \n",
       "TU                         0  \n",
       "UK                         0  \n",
       "\n",
       "[63 rows x 157 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(combined_data['STATE/COUNTRY ID'], combined_data.NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High Level Descriptive Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessment of feature distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Plots for Numerical Columns\n",
    "numeric_columns = combined_data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(7,7))\n",
    "\n",
    "for i in numeric_columns:\n",
    "    sns.distplot(combined_data[i], hist=True, kde=True, color = 'darkblue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "object_columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Snowfall'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplots for Categorical Data\n",
    "object_columns = combined_data.select_dtypes(include=['object']).columns\n",
    "object_columns = object_columns[1:] #  Cannot plot STA\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(7,7))\n",
    "\n",
    "for i in object_columns:\n",
    "    combined_data[i].value_counts().plot(kind='bar')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(combined_data.YR, combined_data.MO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joypy import joyplot\n",
    "feature_data = combined_data[['Date', 'NAME', 'MIN', 'MAX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.NAME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_data = feature_data.query(\"NAME == 'WHEELER/AFB 810.1'\")\n",
    "ridge_data = ridge_data.drop('NAME', axis=1)\n",
    "ridge_data['Date'] = ridge_data['Date'].astype('datetime64')\n",
    "ridge_data['Month'] = ridge_data['Date'].dt.month_name()\n",
    "\n",
    "ridge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "cat_month = CategoricalDtype(\n",
    "    ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "     'July', 'August', 'September', 'October', 'November', 'December']\n",
    ")\n",
    "\n",
    "ridge_data['Month'] = ridge_data['Month'].astype(cat_month)\n",
    "\n",
    "ridge_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "joyplot(\n",
    "    data=ridge_data[['MAX', 'Month']], \n",
    "    by='Month',\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "\n",
    "plt.title('Ridgeline Plot of Max Temperatures in WHEELER/AFB 810.1', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ax, fig = joyplot(\n",
    "    data=ridge_data[['MIN', 'MAX', 'Month']], \n",
    "    by='Month',\n",
    "    column=['MIN', 'MAX'],\n",
    "    color=['#686de0', '#eb4d4b'],\n",
    "    legend=True,\n",
    "    alpha=0.85,\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "plt.title('Ridgeline Plot of Min and Max Temperatures in WHEELER/AFB 810.1', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write clean data to 02_intermediate data folder\n",
    "#weather_summary.to_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/02_intermediate/data_cleaning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - Feature Engineering\n",
    "- Deal with date columns. There are 4 most common methods to transform date to numeric format:\n",
    "    - Unix timestamp: Time since 1970 (not applicable as our data is from period 1940 - 1944\n",
    "    - KSP date formate: Year and quarter are obvious and attempts to retain similar intervals\n",
    "    - Divide into several features (DA / MO / YR): Data already formated to accommodate these features\n",
    "    - Manual Feature Creation: Time from or to an event\n",
    "- Feature Creation:\n",
    "    - Northern/Southern Hemisphere Flag\n",
    "    - Binary Flag for univariate outliers\n",
    "    - Create sensible bins for numerical Variables\n",
    "    - Sine & Cos features (out of scope)\n",
    "    - Average temperature per month/per quarter\n",
    "- Normalization and standardization of features: Precip/Snowfall/SNF/ELEV\n",
    "- Dimensionality Reduction <br>\n",
    "\n",
    "https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159 <br>\n",
    "https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca <br>\n",
    "https://medium.com/@khadijamahanga/using-latitude-and-longitude-data-in-my-machine-learning-problem-541e2651e08c <br>\n",
    "https://towardsdatascience.com/geopandas-101-plot-any-data-with-a-latitude-and-longitude-on-a-map-98e01944b972"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Time Features** <br>\n",
    "Note: From there analysis it is clear that some areas from both the northern and southern hemisphere have been included as part of the research so care should be taken when dealing with datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import calendar\n",
    "\n",
    "def to_ksp_format(datetime):\n",
    "    year = datetime.year\n",
    "    day_from_jan_1 = (datetime - dt.datetime(year, 1, 1)).days\n",
    "    is_leap_year = int(calendar.isleap(year))\n",
    "    \n",
    "    return year + (day_from_jan_1 - 0.5) / (365 + is_leap_year)\n",
    "\n",
    "combined_data['ksp_date'] = combined_data['Date'].apply(to_ksp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arithmetic Features** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Features** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geo-Spatial Data (Latitude & Longitude)**\n",
    "Converting geolocation data into zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average based on the fahrenheit columns\n",
    "weather_summary['MeanTemp_F'] = (weather_summary['MAX'] + weather_summary['MIN'])/2\n",
    "\n",
    "# Create a simplier binary feature for snowfall occurrence\n",
    "weather_summary['Snowfall_bin'] =  np.where(weather_summary.Snowfall.isnull(), 0, 1)\n",
    "\n",
    "# Add full state names to the analysis\n",
    "AMERICAN_STATES_TUPLE = [(\"AL\",\"Alabama\"),\n",
    "                         (\"AK\",\"Alaska\"),\n",
    "                         (\"AZ\",\"Arizona\"),\n",
    "                         (\"AR\",\"Arkansas\"),\n",
    "                         (\"CA\", \"California\"),\n",
    "                         (\"CO\", \"Colorado\"),\n",
    "                         (\"CT\",\"Connecticut\"),\n",
    "                         (\"DC\",\"Washington DC\"),\n",
    "                         (\"DE\",\"Delaware\"),\n",
    "                         (\"FL\",\"Florida\"),\n",
    "                         (\"GA\",\"Georgia\"),\n",
    "                         (\"HI\",\"Hawaii\"),\n",
    "                         (\"ID\",\"Idaho\"),\n",
    "                         (\"IL\",\"Illinois\"),\n",
    "                         (\"IN\",\"Indiana\"),\n",
    "                         (\"IA\",\"Iowa\"),\n",
    "                         (\"KS\",\"Kansas\"),\n",
    "                         (\"KY\",\"Kentucky\"),\n",
    "                         (\"LA\",\"Louisiana\"),\n",
    "                         (\"ME\",\"Maine\"),\n",
    "                         (\"MD\",\"Maryland\"),\n",
    "                         (\"MA\",\"Massachusetts\"),\n",
    "                         (\"MI\",\"Michigan\"),\n",
    "                         (\"MN\",\"Minnesota\"),\n",
    "                         (\"MS\",\"Mississippi\"),\n",
    "                (\"MO\",\"Missouri\"),\n",
    "                (\"MT\",\"Montana\"),\n",
    "                (\"NE\",\"Nebraska\"),\n",
    "                (\"NV\",\"Nevada\"),\n",
    "                (\"NH\",\"New Hampshire\"),\n",
    "                (\"NJ\",\"New Jersey\"),\n",
    "                (\"NM\",\"New Mexico\"),\n",
    "                (\"NY\",\"New York\"),\n",
    "                (\"NC\",\"North Carolina\"),\n",
    "                (\"ND\",\"North Dakota\"),\n",
    "                (\"OH\",\"Ohio\"),\n",
    "                (\"OK\",\"Oklahoma\"),\n",
    "                (\"OR\",\"Oregon\"),\n",
    "                (\"PA\",\"Pennsylvania\"),\n",
    "                (\"RI\",\"Rhode Island\"),\n",
    "                (\"SC\",\"South Carolina\"),\n",
    "                (\"SD\",\"South Dakota\"),\n",
    "                (\"TN\",\"Tennessee\"),\n",
    "                (\"TX\",\"Texas\"),\n",
    "                (\"UT\",\"Utah\"),\n",
    "                (\"VT\",\"Vermont\"),\n",
    "                (\"VA\",\"Virginia\"),\n",
    "                (\"WA\",\"Washington\"),\n",
    "                (\"WV\",\"West Virginia\"),\n",
    "                (\"WI\",\"Wisconsin\"),\n",
    "                (\"WY\",\"Wyoming\")]\n",
    "\n",
    "\n",
    "# Add sine and cos features for seasonal elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write clean data to 02_intermediate data folder\n",
    "weather_summary.to_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/03_processed/data_std_feature_eng.csv')\n",
    "\n",
    "# Save the features to a pickle file\n",
    "\n",
    "\n",
    "#weather_summary_tm.to_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/03_processed/data_tm_feature_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_summary['Snowfall_bin'].value_counts().sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call regplot on each axes\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "\n",
    "sns.displot(weather_summary, x=\"MIN\", ax=ax1)\n",
    "sns.displot(weather_summary, x=\"MAX\", ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(weather_summary, x=\"MAX\", hue=\"YR\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_summary[weather_summary['STA'] == 10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_summary = pd.read_csv('/Users/Rej1992/Documents/GitHub/RegressionModels/data/02_intermediate/data_cleaning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Analysis & Visualization of features**\n",
    "- Timeseries Dataframe: weather_summary_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the data into date order and reset index\n",
    "## Create a new timeseries dataframe \n",
    "weather_summary.set_index('Date', drop=True, inplace=True)\n",
    "weather_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Analysis\n",
    "plt.scatter(weather_summary.DA, weather_summary.MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TimeSeries Analysis \n",
    "# sns.lineplot(x='Date', \n",
    "#              y='MIN', \n",
    "#              data=weather_summarytrans, \n",
    "#              hue='STA'); # ';' is to avoid extra message before plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Location Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis & Expectations to Test**\n",
    "- What are the locations associated with the study?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_min_temperature = Data.loc[0, 'Average Tank Temperature (deg F)']\n",
    "initial_max_temperature = Data.loc[0, 'Average Tank Temperature (deg F)']\n",
    "\n",
    "final_min_temperature = Data.loc[Data.index.max(), 'Average Tank Temperature (deg F)']\n",
    "final_max_temperature = Data.loc[Data.index.max(), 'Average Tank Temperature (deg F)']\n",
    "\n",
    "min_temperature = Data['T_Amb (deg F)'].min()\n",
    "max_temperature = Data['T_Amb (deg F)'].max()\n",
    "\n",
    "min_temperature_sd = Data['T_Amb (deg F)'].sd()\n",
    "max_temperature_sd = Data['T_Amb (deg F)'].sd()\n",
    "\n",
    "min_temperature_avg = Data['T_Amb (deg F)'].mean()\n",
    "max_temperature_avg = Data['T_Amb (deg F)'].mean()\n",
    "\n",
    "min_temperature_median\n",
    "max_temperature_median\n",
    "\n",
    "min_temperature_mode\n",
    "max_temperature_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building \n",
    "- Data partitioning into training, validation and testing sets (set seed)\n",
    "    - Ensure that the range of the test is within the range of the train \n",
    "- Select the model that you would like to use\n",
    "- Hyperparameter tuning is used to fine-tune the model in order to prevent overfitting \n",
    "- Cross-validation is performed to ensure the model performs well on the validation set \n",
    "- Model is applied to the test data set\n",
    "- Save the trained model to a pickle file\n",
    "- Create a learning curve\n",
    "- Assess model bias and variance to deduce model improvement next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Remove date - this needs to have feature engineering applied\n",
    "combined_data.drop(['Date'], axis=1, inplace=True) \n",
    "\n",
    "# create training and testing vars\n",
    "x_train, x_test, y_train, y_test = train_test_split(combined_data, combined_data.MAX, test_size=0.3, random_state=0)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the distribution between the train and test dataset\n",
    "# Sweetviz notes: Only supports numeric & boolean targets currently\n",
    "my_report_train_test = sv.compare([x_train, \"Train\"], [x_test, \"Test\"], \"MAX\")\n",
    "my_report_train_test.show_html() # Not providing a filename will default to SWEETVIZ_REPORT.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SuspiciousTests_Test = pd.DataFrame(columns = ['Filename', 'Test Parameters', 'Code', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
